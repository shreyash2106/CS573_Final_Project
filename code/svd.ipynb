{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0  duration (ms)  danceability  energy  loudness  speechiness  \\\n",
      "0      114604       246022.0         0.709   0.965    -2.686       0.2110   \n",
      "1      199817       217187.0         0.552   0.463    -9.976       0.0292   \n",
      "2          32       266668.0         0.570   0.368    -9.128       0.0329   \n",
      "3       82712       170418.0         0.629   0.832    -5.633       0.0442   \n",
      "4       41910       312413.0         0.510   0.887    -5.569       0.0799   \n",
      "\n",
      "   acousticness  instrumentalness  liveness  valence    tempo     spec_rate  \\\n",
      "0        0.0320          0.025800     0.118    0.699  120.065  8.576469e-07   \n",
      "1        0.4550          0.000166     0.103    0.498   79.312  1.344464e-07   \n",
      "2        0.0514          0.000000     0.108    0.136  139.937  1.233744e-07   \n",
      "3        0.0547          0.203000     0.221    0.120  123.975  2.593623e-07   \n",
      "4        0.0194          0.000000     0.225    0.255  134.029  2.557512e-07   \n",
      "\n",
      "   labels                                   uri  user_id  group_no  \n",
      "0       1  spotify:track:2QcbhQWfVD5QcTJzAtpYsg        1         2  \n",
      "1       0  spotify:track:3zsrxImXgoplvMZla6sXk4        1         2  \n",
      "2       0  spotify:track:3tzlgaWjqZJX0fq2hiQW62        1         2  \n",
      "3       2  spotify:track:062ew4tNbEHK33H8QN3P6H        1         2  \n",
      "4       2  spotify:track:7lhULmqN96IMncW8iFxYMn        1         2  \n"
     ]
    }
   ],
   "source": [
    "user_data = pd.read_csv('../datasets/simulated_user_dataset.csv')\n",
    "print(user_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['duration (ms)', 'danceability', 'energy', 'loudness', 'speechiness',\n",
      "       'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo',\n",
      "       'spec_rate', 'labels', 'uri', 'user_id', 'group_no'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# drop column 'Unnamed: 0'\n",
    "user_data = user_data.drop('Unnamed: 0', axis=1)\n",
    "print(user_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse.linalg import svds\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "def create_user_item_matrix(df):\n",
    "    \"\"\"\n",
    "    Step 1: Create the user-item matrix\n",
    "    - Rows represent users\n",
    "    - Columns represent songs (items)\n",
    "    - Values represent the interaction score\n",
    "    \"\"\"\n",
    "    # First, let's create an interaction score based on the features\n",
    "    feature_columns = [\n",
    "        'danceability', 'energy', 'loudness', 'speechiness',\n",
    "        'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo',\n",
    "        'duration (ms)', 'spec_rate', 'labels'\n",
    "    ]\n",
    "    \n",
    "    # Normalize the features to 0-1 scale\n",
    "    scaler = MinMaxScaler()\n",
    "    normalized_features = scaler.fit_transform(df[feature_columns])\n",
    "    \n",
    "    # Create an interaction score (average of normalized features)\n",
    "    df['interaction_score'] = np.mean(normalized_features, axis=1)\n",
    "    \n",
    "    # Create the user-item matrix\n",
    "    user_item_matrix = df.pivot_table(\n",
    "        index='user_id',\n",
    "        columns='uri',\n",
    "        values='interaction_score',\n",
    "        fill_value=0\n",
    "    )\n",
    "    \n",
    "    return user_item_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def perform_svd(matrix, k=10):\n",
    "    \"\"\"\n",
    "    Step 2: Perform SVD on the matrix\n",
    "    - Decompose matrix into U, Sigma, and V matrices\n",
    "    - k is the number of latent factors\n",
    "    \"\"\"\n",
    "    # Convert to numpy array\n",
    "    matrix_numpy = matrix.values\n",
    "    \n",
    "    # Center the matrix (subtract mean)\n",
    "    matrix_mean = np.mean(matrix_numpy, axis=1)\n",
    "    matrix_centered = matrix_numpy - matrix_mean.reshape(-1, 1)\n",
    "    \n",
    "    # Perform SVD\n",
    "    U, sigma, Vt = svds(matrix_centered, k=k)\n",
    "    \n",
    "    # Convert sigma to diagonal matrix\n",
    "    sigma = np.diag(sigma)\n",
    "    \n",
    "    return U, sigma, Vt, matrix_mean\n",
    "\n",
    "def reconstruct_matrix(U, sigma, Vt, matrix_mean):\n",
    "    \"\"\"\n",
    "    Step 3: Reconstruct the matrix to get predictions\n",
    "    - Multiply U, sigma, and V transpose\n",
    "    - Add back the mean\n",
    "    \"\"\"\n",
    "    # Reconstruct the matrix\n",
    "    predictions = np.dot(np.dot(U, sigma), Vt)\n",
    "    \n",
    "    # Add the mean back\n",
    "    predictions += matrix_mean.reshape(-1, 1)\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "def get_recommendations(predictions, user_item_matrix, user_id, n_recommendations=5):\n",
    "    \"\"\"\n",
    "    Step 4: Generate recommendations for a user\n",
    "    - Find songs the user hasn't interacted with\n",
    "    - Rank them by predicted score\n",
    "    \"\"\"\n",
    "    # Get user index\n",
    "    user_idx = user_item_matrix.index.get_loc(user_id)\n",
    "    \n",
    "    # Get song indices and names\n",
    "    song_indices = np.arange(user_item_matrix.shape[1])\n",
    "    song_names = user_item_matrix.columns\n",
    "    \n",
    "    # Get user's predictions\n",
    "    user_predictions = predictions[user_idx]\n",
    "    \n",
    "    # Get indices of songs user hasn't interacted with\n",
    "    user_songs = user_item_matrix.iloc[user_idx].values\n",
    "    unlistened_songs = song_indices[user_songs == 0]\n",
    "    \n",
    "    # Get predictions for unlistened songs\n",
    "    unlistened_predictions = user_predictions[unlistened_songs]\n",
    "    \n",
    "    # Get top N recommendations\n",
    "    top_n_idx = np.argsort(unlistened_predictions)[-n_recommendations:][::-1]\n",
    "    recommended_song_indices = unlistened_songs[top_n_idx]\n",
    "    recommended_songs = song_names[recommended_song_indices]\n",
    "    \n",
    "    return recommended_songs, user_predictions[recommended_song_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_svd_pipeline(df, n_factors=10):\n",
    "    \"\"\"\n",
    "    Run the complete SVD pipeline\n",
    "    \"\"\"\n",
    "    # Step 1: Create user-item matrix\n",
    "    print(\"Creating user-item matrix...\")\n",
    "    user_item_matrix = create_user_item_matrix(df)\n",
    "    print(f\"Matrix shape: {user_item_matrix.shape}\")\n",
    "    \n",
    "    # Step 2: Perform SVD\n",
    "    print(\"\\nPerforming SVD...\")\n",
    "    U, sigma, Vt, matrix_mean = perform_svd(user_item_matrix, k=n_factors)\n",
    "    print(f\"U shape: {U.shape}\")\n",
    "    print(f\"Sigma shape: {sigma.shape}\")\n",
    "    print(f\"V^T shape: {Vt.shape}\")\n",
    "    \n",
    "    # Step 3: Generate predictions\n",
    "    print(\"\\nGenerating predictions...\")\n",
    "    predictions = reconstruct_matrix(U, sigma, Vt, matrix_mean)\n",
    "    \n",
    "    return user_item_matrix, predictions\n",
    "\n",
    "# Example usage\n",
    "def demonstrate_recommendations(df):\n",
    "    \"\"\"\n",
    "    Demonstrate the recommendation system\n",
    "    \"\"\"\n",
    "    # Run SVD pipeline\n",
    "    user_item_matrix, predictions = main_svd_pipeline(df)\n",
    "    \n",
    "    # Get recommendations for a sample user\n",
    "    i = np.random.randint(user_item_matrix.shape[0])\n",
    "    sample_user = user_item_matrix.index[i]\n",
    "    print(f\"\\nGetting recommendations for user {sample_user}...\")\n",
    "    recommended_songs, pred_scores = get_recommendations(\n",
    "        predictions, \n",
    "        user_item_matrix, \n",
    "        sample_user\n",
    "    )\n",
    "    \n",
    "    return recommended_songs, pred_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating user-item matrix...\n",
      "Matrix shape: (100, 82752)\n",
      "\n",
      "Performing SVD...\n",
      "U shape: (100, 10)\n",
      "Sigma shape: (10, 10)\n",
      "V^T shape: (10, 82752)\n",
      "\n",
      "Generating predictions...\n"
     ]
    }
   ],
   "source": [
    "recommended_songs, pred_scores = demonstrate_recommendations(user_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
