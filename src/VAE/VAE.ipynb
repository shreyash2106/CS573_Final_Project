{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "VAE FOR SONG RECOMMENDATION"
      ],
      "metadata": {
        "id": "2VfX2M-R3WE2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "\n",
        "data_file = \"/content/drive/MyDrive/CS573_Final_Project-main/datasets/user_month_datasets/user1_1month_listening_history.csv\"\n",
        "data = pd.read_csv(data_file)\n",
        "\n",
        "# Select numerical columns for VAE\n",
        "numerical_columns = [\n",
        "    \"duration (ms)\", \"danceability\", \"energy\", \"loudness\",\n",
        "    \"speechiness\", \"acousticness\", \"instrumentalness\", \"liveness\",\n",
        "    \"valence\", \"tempo\", \"spec_rate\"\n",
        "]\n",
        "features = data[numerical_columns].values\n",
        "\n",
        "# Scaling the features\n",
        "scaler = MinMaxScaler()\n",
        "scaled_features = scaler.fit_transform(features)\n",
        "\n",
        "X_train, X_temp = train_test_split(scaled_features, test_size=0.3, random_state=42)\n",
        "X_val, X_test = train_test_split(X_temp, test_size=0.5, random_state=42)\n",
        "\n",
        "\n",
        "class SongDataset(Dataset):\n",
        "    def __init__(self, data):\n",
        "        self.data = torch.tensor(data, dtype=torch.float32)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.data[idx]\n",
        "\n",
        "train_dataset = SongDataset(X_train)\n",
        "val_dataset = SongDataset(X_val)\n",
        "test_dataset = SongDataset(X_test)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
        "\n"
      ],
      "metadata": {
        "id": "GgBP_kQAoH7k"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# VAE Model\n",
        "class VAE(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, latent_dim):\n",
        "        super(VAE, self).__init__()\n",
        "        # Encoder\n",
        "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
        "        self.fc2_mean = nn.Linear(hidden_dim, latent_dim)\n",
        "        self.fc2_logvar = nn.Linear(hidden_dim, latent_dim)\n",
        "        # Decoder\n",
        "        self.fc3 = nn.Linear(latent_dim, hidden_dim)\n",
        "        self.fc4 = nn.Linear(hidden_dim, input_dim)\n",
        "\n",
        "    def encode(self, x):\n",
        "        h = torch.relu(self.fc1(x))\n",
        "        mean = self.fc2_mean(h)\n",
        "        logvar = self.fc2_logvar(h)\n",
        "        return mean, logvar\n",
        "\n",
        "    def reparameterize(self, mean, logvar):\n",
        "        std = torch.exp(0.5 * logvar)\n",
        "        eps = torch.randn_like(std)\n",
        "        return mean + eps * std\n",
        "\n",
        "    def decode(self, z):\n",
        "        h = torch.relu(self.fc3(z))\n",
        "        return torch.sigmoid(self.fc4(h))\n",
        "\n",
        "    def forward(self, x):\n",
        "        mean, logvar = self.encode(x)\n",
        "        z = self.reparameterize(mean, logvar)\n",
        "        reconstruction = self.decode(z)\n",
        "        return reconstruction, mean, logvar\n",
        "\n",
        "# Loss function and optimizer (KL DIVERGENCE)\n",
        "def vae_loss(reconstructed, original, mean, logvar):\n",
        "    recon_loss = nn.MSELoss()(reconstructed, original)\n",
        "    kl_div = -0.5 * torch.sum(1 + logvar - mean.pow(2) - logvar.exp()) / original.size(0)\n",
        "    return recon_loss + kl_div"
      ],
      "metadata": {
        "id": "D2I0zHn534QZ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_dim = len(numerical_columns)\n",
        "hidden_dim = 64\n",
        "latent_dim = 16\n",
        "learning_rate = 1e-3\n",
        "num_epochs = 50\n",
        "\n",
        "model = VAE(input_dim, hidden_dim, latent_dim)\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for batch in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        reconstructed, mean, logvar = model(batch)\n",
        "        loss = vae_loss(reconstructed, batch, mean, logvar)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    print(f\"Epoch {epoch + 1}, Loss: {total_loss / len(train_loader)}\")\n",
        "\n",
        "#  Generating recommendations\n",
        "def recommend_similar_songs(song_features, top_k=10):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        # Encode input song features into latent space\n",
        "        song_tensor = torch.tensor(song_features, dtype=torch.float32)\n",
        "        mean, logvar = model.encode(song_tensor)\n",
        "        latent_space = model.reparameterize(mean, logvar).numpy()\n",
        "\n",
        "        # Compute similarity in latent space\n",
        "        all_latents = []\n",
        "        song_indices = []  # Keep track of original indices for recommendations\n",
        "        for idx, data_batch in enumerate(train_loader):\n",
        "            mean, logvar = model.encode(data_batch)\n",
        "            z = model.reparameterize(mean, logvar)\n",
        "            all_latents.append(z.numpy())\n",
        "            song_indices.extend(range(idx * train_loader.batch_size,\n",
        "                                      idx * train_loader.batch_size + len(data_batch)))\n",
        "\n",
        "        all_latents = np.concatenate(all_latents, axis=0)\n",
        "\n",
        "        # Compute similarities\n",
        "        similarities = cosine_similarity(latent_space, all_latents)\n",
        "        top_indices = np.argsort(-similarities, axis=1)[:, :top_k].flatten()\n",
        "\n",
        "        # Map back to original song indices\n",
        "        original_indices = [song_indices[i] for i in top_indices]\n",
        "        return data.iloc[original_indices]\n",
        "\n",
        "\n",
        "song_index = 0  # Index of the song to recommend based on\n",
        "input_song_features = scaled_features[song_index].reshape(1, -1)\n",
        "recommended_songs = recommend_similar_songs(input_song_features)\n",
        "print(recommended_songs['uri'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vZiqZvWT4BUj",
        "outputId": "9f1e95ee-a441-44ca-d57e-bced9567a85c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 0.2022225129253724\n",
            "Epoch 2, Loss: 0.08875186434563469\n",
            "Epoch 3, Loss: 0.07414564577972188\n",
            "Epoch 4, Loss: 0.06909756976015427\n",
            "Epoch 5, Loss: 0.06615586206316948\n",
            "Epoch 6, Loss: 0.06454910798107877\n",
            "Epoch 7, Loss: 0.06347703626927208\n",
            "Epoch 8, Loss: 0.06281004079124507\n",
            "Epoch 9, Loss: 0.062298126299591625\n",
            "Epoch 10, Loss: 0.061734111870036405\n",
            "Epoch 11, Loss: 0.06147115589941249\n",
            "Epoch 12, Loss: 0.061315379160292005\n",
            "Epoch 13, Loss: 0.06102457094718428\n",
            "Epoch 14, Loss: 0.06086958638008903\n",
            "Epoch 15, Loss: 0.06059109726372887\n",
            "Epoch 16, Loss: 0.060362689635332895\n",
            "Epoch 17, Loss: 0.060691792956169915\n",
            "Epoch 18, Loss: 0.06039837879293105\n",
            "Epoch 19, Loss: 0.060134528533500785\n",
            "Epoch 20, Loss: 0.06010258964755956\n",
            "Epoch 21, Loss: 0.06011613305000698\n",
            "Epoch 22, Loss: 0.06037151550545412\n",
            "Epoch 23, Loss: 0.06010124503689654\n",
            "Epoch 24, Loss: 0.059874408385332895\n",
            "Epoch 25, Loss: 0.05998741506653674\n",
            "Epoch 26, Loss: 0.060032986761892546\n",
            "Epoch 27, Loss: 0.06000216217602\n",
            "Epoch 28, Loss: 0.059763136593734514\n",
            "Epoch 29, Loss: 0.05973028479253545\n",
            "Epoch 30, Loss: 0.059947238687206715\n",
            "Epoch 31, Loss: 0.05963863235186128\n",
            "Epoch 32, Loss: 0.05962705590269145\n",
            "Epoch 33, Loss: 0.05941040901576772\n",
            "Epoch 34, Loss: 0.059585904812111574\n",
            "Epoch 35, Loss: 0.05953939719235196\n",
            "Epoch 36, Loss: 0.059735734234837926\n",
            "Epoch 37, Loss: 0.05966883371858036\n",
            "Epoch 38, Loss: 0.059705440831535006\n",
            "Epoch 39, Loss: 0.059697641826727814\n",
            "Epoch 40, Loss: 0.05943135303609511\n",
            "Epoch 41, Loss: 0.05963002780781073\n",
            "Epoch 42, Loss: 0.05933615894002073\n",
            "Epoch 43, Loss: 0.05958019744823961\n",
            "Epoch 44, Loss: 0.05949225232881658\n",
            "Epoch 45, Loss: 0.059685995692715925\n",
            "Epoch 46, Loss: 0.05939354287350879\n",
            "Epoch 47, Loss: 0.05927861503818456\n",
            "Epoch 48, Loss: 0.05952714712304227\n",
            "Epoch 49, Loss: 0.059378850985975826\n",
            "Epoch 50, Loss: 0.05929289473330274\n",
            "12      spotify:track:2yUk5hBWGU9beINGlx5Pk1\n",
            "761     spotify:track:41sdDRca6UhPB5MLZjpz1L\n",
            "91      spotify:track:4rwOe0jaZXyfb5VAUrkXK9\n",
            "963     spotify:track:0S1JU2YzdbhaH7IAs3E9Md\n",
            "332     spotify:track:29JFzx7V6i2NEh6C1xcOo7\n",
            "571     spotify:track:6juLaduD4STCUDWT0AYun4\n",
            "964     spotify:track:7xBW2k8HbYD4m18E49gdVk\n",
            "396     spotify:track:5l4h3AwBfG18WkXAuV7Ilg\n",
            "398     spotify:track:3bB2G1eIWcwfHpaxPhlQRj\n",
            "1007    spotify:track:2WhKCglDEsiNAtdrtd28Da\n",
            "Name: uri, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extraction of Song Names using Spotify API"
      ],
      "metadata": {
        "id": "5LsYrx9d4JBu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install spotipy\n",
        "import spotipy\n",
        "from spotipy.oauth2 import SpotifyClientCredentials\n",
        "\n",
        "#Authentication with Spotify API\n",
        "client_id = \"75d0ab19dcdc4db7821a27bf07df72a0\"\n",
        "client_secret = \"f64897e446834d7cb83b1c90916242df\"\n",
        "\n",
        "sp = spotipy.Spotify(auth_manager=SpotifyClientCredentials(client_id=client_id, client_secret=client_secret))\n",
        "\n",
        "# Function to get song names from URIs\n",
        "def get_song_names(uris):\n",
        "    song_names = []\n",
        "    for uri in uris:\n",
        "        try:\n",
        "            track = sp.track(uri)\n",
        "            song_names.append({\n",
        "                \"name\": track['name'],\n",
        "                \"artist\": track['artists'][0]['name'],\n",
        "                \"album\": track['album']['name'],\n",
        "                \"uri\": uri\n",
        "            })\n",
        "        except Exception as e:\n",
        "            print(f\"Error fetching details for URI {uri}: {e}\")\n",
        "            song_names.append({\"name\": \"Unknown\", \"artist\": \"Unknown\", \"album\": \"Unknown\", \"uri\": uri})\n",
        "    return song_names\n",
        "\n",
        "\n",
        "recommended_uris = recommended_songs['uri']\n",
        "print(recommended_songs)\n",
        "song_metadata = get_song_names(recommended_uris)\n",
        "for song in song_metadata:\n",
        "    print(f\"Name: {song['name']}, Artist: {song['artist']}, Album: {song['album']}, URI: {song['uri']}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "WIdScYCTqMKs",
        "outputId": "9e20584f-6943-491d-f1d2-a6d95c85a472"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting spotipy\n",
            "  Downloading spotipy-2.24.0-py3-none-any.whl.metadata (4.9 kB)\n",
            "Collecting redis>=3.5.3 (from spotipy)\n",
            "  Downloading redis-5.2.0-py3-none-any.whl.metadata (9.1 kB)\n",
            "Requirement already satisfied: requests>=2.25.0 in /usr/local/lib/python3.10/dist-packages (from spotipy) (2.32.3)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.10/dist-packages (from spotipy) (2.2.3)\n",
            "Requirement already satisfied: async-timeout>=4.0.3 in /usr/local/lib/python3.10/dist-packages (from redis>=3.5.3->spotipy) (4.0.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.25.0->spotipy) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.25.0->spotipy) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.25.0->spotipy) (2024.8.30)\n",
            "Downloading spotipy-2.24.0-py3-none-any.whl (30 kB)\n",
            "Downloading redis-5.2.0-py3-none-any.whl (261 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m261.4/261.4 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: redis, spotipy\n",
            "Successfully installed redis-5.2.0 spotipy-2.24.0\n",
            "      duration (ms)  danceability  energy  loudness  speechiness  \\\n",
            "12         402587.0      0.559816   0.270  0.297548     0.313907   \n",
            "761        214379.0      0.649780   0.529  0.601850     0.582207   \n",
            "91         229680.0      0.356324   0.414  0.427953     0.184768   \n",
            "963        248750.0      0.631573   0.200  0.183293     0.187417   \n",
            "332        222179.0      0.801864   0.158  0.251817     0.515894   \n",
            "571        217088.0      0.647638   0.787  0.679439     0.211921   \n",
            "964         85848.0      0.574810   0.318  0.289951     0.205298   \n",
            "396        310560.0      0.595159   0.762  0.599684     0.174172   \n",
            "398        240053.0      0.846846   0.293  0.555164     0.462914   \n",
            "1007       172853.0      0.617650   0.706  0.647324     0.218543   \n",
            "\n",
            "      acousticness  instrumentalness  liveness  valence     tempo  \\\n",
            "12        0.864458          0.872000  0.248227    0.451  0.545177   \n",
            "761       0.494980          0.000002  0.142790    0.709  0.334476   \n",
            "91        0.578313          0.002500  0.184397    0.361  0.835210   \n",
            "963       0.906627          0.841000  0.222459    0.394  0.377452   \n",
            "332       0.990964          0.525000  0.210165    0.525  0.400465   \n",
            "571       0.002580          0.000000  0.763593    0.199  0.641312   \n",
            "964       0.551205          0.868000  0.218913    0.356  0.268838   \n",
            "396       0.018775          0.000582  0.702128    0.808  0.398503   \n",
            "398       0.117470          0.002410  0.164775    0.517  0.284786   \n",
            "1007      0.733936          0.000000  0.749409    0.702  0.601686   \n",
            "\n",
            "         spec_rate  labels                                   uri  user_id  \\\n",
            "12    1.177385e-07     3.0  spotify:track:2yUk5hBWGU9beINGlx5Pk1        1   \n",
            "761   4.754654e-07     1.0  spotify:track:41sdDRca6UhPB5MLZjpz1L        1   \n",
            "91    1.214734e-07     0.0  spotify:track:4rwOe0jaZXyfb5VAUrkXK9        1   \n",
            "963   1.137688e-07     0.0  spotify:track:0S1JU2YzdbhaH7IAs3E9Md        1   \n",
            "332   3.506182e-07     3.0  spotify:track:29JFzx7V6i2NEh6C1xcOo7        1   \n",
            "571   1.474057e-07     1.0  spotify:track:6juLaduD4STCUDWT0AYun4        1   \n",
            "964   3.611033e-07     3.0  spotify:track:7xBW2k8HbYD4m18E49gdVk        1   \n",
            "396   8.468573e-08     0.0  spotify:track:5l4h3AwBfG18WkXAuV7Ilg        1   \n",
            "398   2.911857e-07     1.0  spotify:track:3bB2G1eIWcwfHpaxPhlQRj        1   \n",
            "1007  1.909137e-07     1.0  spotify:track:2WhKCglDEsiNAtdrtd28Da        1   \n",
            "\n",
            "      group_no  day  \n",
            "12           2    1  \n",
            "761          2   16  \n",
            "91           2    2  \n",
            "963          2   20  \n",
            "332          2    7  \n",
            "571          2   12  \n",
            "964          2   20  \n",
            "396          2    8  \n",
            "398          2    8  \n",
            "1007         2   21  \n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-ee152497b077>\u001b[0m in \u001b[0;36m<cell line: 31>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0mrecommended_uris\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecommended_songs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'uri'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecommended_songs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0msong_metadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_song_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecommended_uris\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msong\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msong_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Name: {song['name']}, Artist: {song['artist']}, Album: {song['album']}, URI: {song['uri']}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-ee152497b077>\u001b[0m in \u001b[0;36mget_song_names\u001b[0;34m(uris)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0muri\u001b[0m \u001b[0;32min\u001b[0m \u001b[0muris\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             \u001b[0mtrack\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muri\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m             song_names.append({\n\u001b[1;32m     18\u001b[0m                 \u001b[0;34m\"name\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/spotipy/client.py\u001b[0m in \u001b[0;36mtrack\u001b[0;34m(self, track_id, market)\u001b[0m\n\u001b[1;32m    373\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m         \u001b[0mtrid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"track\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 375\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"tracks/\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtrid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmarket\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmarket\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtracks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmarket\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/spotipy/client.py\u001b[0m in \u001b[0;36m_get\u001b[0;34m(self, url, args, payload, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 327\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_internal_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"GET\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpayload\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_post\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpayload\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/spotipy/client.py\u001b[0m in \u001b[0;36m_internal_call\u001b[0;34m(self, method, url, payload, params)\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m             response = self._session.request(\n\u001b[0m\u001b[1;32m    271\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproxies\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproxies\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m                 \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequests_timeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    587\u001b[0m         }\n\u001b[1;32m    588\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 703\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    704\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 667\u001b[0;31m             resp = conn.urlopen(\n\u001b[0m\u001b[1;32m    668\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m                 \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    940\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m             \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrain_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m             \u001b[0mretries\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    943\u001b[0m             \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Retry: %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m             return self.urlopen(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/util/retry.py\u001b[0m in \u001b[0;36msleep\u001b[0;34m(self, response)\u001b[0m\n\u001b[1;32m    357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrespect_retry_after_header\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m             \u001b[0mslept\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep_for_retry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mslept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/util/retry.py\u001b[0m in \u001b[0;36msleep_for_retry\u001b[0;34m(self, response)\u001b[0m\n\u001b[1;32m    336\u001b[0m         \u001b[0mretry_after\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_retry_after\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mretry_after\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 338\u001b[0;31m             \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretry_after\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    339\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#In this section we do:\n",
        "*VAE Training:* Train 10 separate VAEs, one for each user. <br>\n",
        "*Generation of Recommendations:* Generate song recommendations for each VAE (each user). <br>\n",
        "*Saving Outputs:* Save models and recommendations for evaluation. <br>"
      ],
      "metadata": {
        "id": "m1H1dlZx4O_6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "metadata": {
        "id": "ANQSM8OvrDKI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6360547-2e72-47b7-d11c-295048ea2675"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics.pairwise import cosine_similarity"
      ],
      "metadata": {
        "id": "6Rqza7CG5E5Q"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "USER_DATASETS_FOLDER = \"/content/drive/MyDrive/CS573_Final_Project-main/datasets/user_month_datasets/\"\n",
        "MODELS_FOLDER = \"/content/drive/MyDrive/VAE/vae_models/\"\n",
        "OUTPUT_FILE = \"/content/drive/MyDrive/VAE/vae_recommendations/vae_recommendations.json\"\n",
        "#os.makedirs(MODELS_FOLDER, exist_ok=True)\n"
      ],
      "metadata": {
        "id": "Sq3J37W95L5c"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# VAE model definition\n",
        "class VAE(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, latent_dim):\n",
        "        super(VAE, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
        "        self.fc2_mean = nn.Linear(hidden_dim, latent_dim)\n",
        "        self.fc2_logvar = nn.Linear(hidden_dim, latent_dim)\n",
        "        self.fc3 = nn.Linear(latent_dim, hidden_dim)\n",
        "        self.fc4 = nn.Linear(hidden_dim, input_dim)\n",
        "\n",
        "    def encode(self, x):\n",
        "        h = torch.relu(self.fc1(x))\n",
        "        mean = self.fc2_mean(h)\n",
        "        logvar = self.fc2_logvar(h)\n",
        "        return mean, logvar\n",
        "\n",
        "    def reparameterize(self, mean, logvar):\n",
        "        std = torch.exp(0.5 * logvar)\n",
        "        eps = torch.randn_like(std)\n",
        "        return mean + eps * std\n",
        "\n",
        "    def decode(self, z):\n",
        "        h = torch.relu(self.fc3(z))\n",
        "        return torch.sigmoid(self.fc4(h))\n",
        "\n",
        "    def forward(self, x):\n",
        "        mean, logvar = self.encode(x)\n",
        "        z = self.reparameterize(mean, logvar)\n",
        "        reconstruction = self.decode(z)\n",
        "        return reconstruction, mean, logvar\n",
        "\n",
        "\n",
        "class SongDataset(Dataset):\n",
        "    def __init__(self, data):\n",
        "        self.data = torch.tensor(data, dtype=torch.float32)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.data[idx]\n",
        "\n",
        "# Loss function with kl divergence\n",
        "def vae_loss(reconstructed, original, mean, logvar):\n",
        "    recon_loss = nn.MSELoss()(reconstructed, original)\n",
        "    kl_div = -0.5 * torch.sum(1 + logvar - mean.pow(2) - mean.pow(2) - logvar.exp()) / original.size(0)\n",
        "    return recon_loss + kl_div\n"
      ],
      "metadata": {
        "id": "eafR9Ua45KR_"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Training function for each VAE\n",
        "def train_vae(features, input_dim, hidden_dim, latent_dim, num_epochs, learning_rate):\n",
        "    dataset = SongDataset(features)\n",
        "    dataloader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
        "    model = VAE(input_dim, hidden_dim, latent_dim)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    model.train()\n",
        "    for epoch in range(num_epochs):\n",
        "        total_loss = 0\n",
        "        for batch in dataloader:\n",
        "            optimizer.zero_grad()\n",
        "            reconstructed, mean, logvar = model(batch)\n",
        "            loss = vae_loss(reconstructed, batch, mean, logvar)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "    return model\n",
        "\n",
        "# Recommendation function\n",
        "def recommend_similar_songs(model, features, data, top_k=10):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        song_tensor = torch.tensor(features, dtype=torch.float32)\n",
        "        mean, logvar = model.encode(song_tensor)\n",
        "        latent_space = model.reparameterize(mean, logvar).numpy()\n",
        "        similarities = cosine_similarity(latent_space, latent_space)\n",
        "        recommendations = np.argsort(-similarities, axis=1)[:, :top_k]\n",
        "        return [\n",
        "            data['uri'].iloc[idx] for idx in recommendations[0]\n",
        "        ]\n",
        "\n",
        "# Main function to process users\n",
        "def process_users(hidden_dim=64, latent_dim=16, num_epochs=50, learning_rate=1e-3, max_users=10, top_k=10):\n",
        "    playlists = {}\n",
        "    user_count = 0\n",
        "    for file in os.listdir(USER_DATASETS_FOLDER):\n",
        "        if file.endswith(\".csv\") and user_count < max_users:\n",
        "            user_id = file.split(\"_\")[0].replace(\"user\", \"\")\n",
        "            print(f\"Processing User {user_id}...\")\n",
        "\n",
        "            # Loading and preprocessing user data\n",
        "            user_data = pd.read_csv(os.path.join(USER_DATASETS_FOLDER, file))\n",
        "            numerical_columns = [\n",
        "                \"duration (ms)\", \"danceability\", \"energy\", \"loudness\",\n",
        "                \"speechiness\", \"acousticness\", \"instrumentalness\", \"liveness\",\n",
        "                \"valence\", \"tempo\", \"spec_rate\"\n",
        "            ]\n",
        "            features = user_data[numerical_columns].values\n",
        "            scaler = MinMaxScaler()\n",
        "            scaled_features = scaler.fit_transform(features)\n",
        "\n",
        "            # Train a single VAE for each user\n",
        "            input_dim = len(numerical_columns)\n",
        "            print(f\"Training VAE for User {user_id}...\")\n",
        "            model = train_vae(scaled_features, input_dim, hidden_dim, latent_dim, num_epochs, learning_rate)\n",
        "\n",
        "            # Saving of the model\n",
        "            model_path = os.path.join(MODELS_FOLDER, f\"user_{user_id}_vae.pth\")\n",
        "            torch.save(model.state_dict(), model_path)\n",
        "\n",
        "            # Generating recommendations for each user\n",
        "            recommended_uris = recommend_similar_songs(model, scaled_features, user_data, top_k=top_k)\n",
        "            playlists[user_id] = recommended_uris\n",
        "\n",
        "            user_count += 1\n",
        "\n",
        "    # Save all recommendations to a single JSON file\n",
        "    with open(OUTPUT_FILE, \"w\") as f:\n",
        "        json.dump(playlists, f)\n",
        "\n",
        "    print(f\"All recommendations saved to {OUTPUT_FILE}\")\n",
        "\n",
        "process_users(top_k=10)  # top_k can be modified to change the number of recommendations per user\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e7pdUjXJ2Iev",
        "outputId": "caca4778-e7f2-4c0b-a94d-980a46332ecd"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing User 7...\n",
            "Training VAE for User 7...\n",
            "Processing User 8...\n",
            "Training VAE for User 8...\n",
            "Processing User 6...\n",
            "Training VAE for User 6...\n",
            "Processing User 9...\n",
            "Training VAE for User 9...\n",
            "Processing User 5...\n",
            "Training VAE for User 5...\n",
            "Processing User 2...\n",
            "Training VAE for User 2...\n",
            "Processing User 10...\n",
            "Training VAE for User 10...\n",
            "Processing User 3...\n",
            "Training VAE for User 3...\n",
            "Processing User 1...\n",
            "Training VAE for User 1...\n",
            "Processing User 4...\n",
            "Training VAE for User 4...\n",
            "All recommendations saved to /content/drive/MyDrive/VAE/vae_recommendations/vae_recommendations.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0U_Bmn8z28MZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}