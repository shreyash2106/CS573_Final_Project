{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import openai\n",
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_id = '75d0ab19dcdc4db7821a27bf07df72a0'  # Replace with your Spotify client ID\n",
    "client_secret = 'f64897e446834d7cb83b1c90916242df'  # Replace with your Spotify client secret\n",
    "client_credentials_manager = SpotifyClientCredentials(client_id=client_id, client_secret=client_secret)\n",
    "sp = spotipy.Spotify(client_credentials_manager=client_credentials_manager)\n",
    "\n",
    "# Function to extract song names from Spotify URLs\n",
    "def get_song_names_from_url(song_uris):\n",
    "    song_names = []\n",
    "    for uri in song_uris:\n",
    "        try:\n",
    "            track_id = uri.split(\":\")[-1]  # Extract the track ID from the URI\n",
    "            track_info = sp.track(track_id)  # Get track information\n",
    "            song_name = track_info['name']  # Extract song name\n",
    "            artist_name = track_info['artists'][0]['name']  # Extract artist name\n",
    "            song_names.append(f\"{song_name} by {artist_name}\")\n",
    "        except Exception as e:\n",
    "            song_names.append(f\"Error retrieving song for URI: {uri} ({e})\")\n",
    "    return song_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"api_key.txt\", \"r\") as f:\n",
    "    key = f.readline().strip()\n",
    "\n",
    "from openai import OpenAI\n",
    "client = OpenAI(api_key=key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../../datasets/seven_day_listening_history.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prompt_features(prompt):\n",
    "    try:\n",
    "        chat_completion = client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",  # Specify the model\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": \"You are a music expert.\",\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": f\"Given the playlist prompt: '{prompt}', assign values between 0 and 1 for these features: acousticness, danceability, energy, instrumentalness, liveness, loudness, speechiness, valence, and tempo. Respond with only a list of values in Python list format.\",\n",
    "                }\n",
    "            ],\n",
    "            temperature=0.4\n",
    "        )\n",
    "\n",
    "        # Extract the content from the response\n",
    "        response_message = chat_completion.choices[0].message.content.strip()\n",
    "        print(\"Response from LLM:\", response_message)  # Debugging step\n",
    "\n",
    "        # Directly evaluate the list (since the LLM is instructed to return a Python-style list)\n",
    "        feature_scores = eval(response_message)\n",
    "        return feature_scores\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching prompt features: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response from LLM: [0.2, 0.8, 0.9, 0.1, 0.5, 0.85, 0.1, 0.8, 0.9]\n"
     ]
    }
   ],
   "source": [
    "features = [\n",
    "    \"acousticness\", \"danceability\", \"energy\", \"instrumentalness\",\n",
    "    \"liveness\", \"valence\", \"tempo\", \"loudness\", \"speechiness\"\n",
    "]\n",
    "scaler = MinMaxScaler()\n",
    "data[features] = scaler.fit_transform(data[features])\n",
    "song_vectors = data[features].values\n",
    "normalized_vectors = song_vectors / np.linalg.norm(song_vectors, axis=1, keepdims=True)\n",
    "unique_indices = list({tuple(vec): i for i, vec in enumerate(normalized_vectors)}.values())\n",
    "data = data.iloc[unique_indices].reset_index(drop=True)\n",
    "\n",
    "# Compute Euclidean distances\n",
    "def compute_distance(song, prompt_features):\n",
    "    song_features = song[features].values\n",
    "    return np.linalg.norm(song_features - np.array(prompt_features))\n",
    "\n",
    "# Main logic to generate a playlist\n",
    "def generate_playlists(prompt, user_ids=None, num_songs=5):\n",
    "    # Fetch features for the prompt\n",
    "    prompt_features = get_prompt_features(prompt)\n",
    "    if prompt_features is None:\n",
    "        print(\"Failed to fetch prompt features.\")\n",
    "        return\n",
    "\n",
    "    if user_ids is None:\n",
    "        user_ids = data[\"user_id\"].unique()\n",
    "    else:\n",
    "        user_ids = [uid for uid in user_ids if uid in data[\"user_id\"].unique()]\n",
    "\n",
    "    all_playlists = {}  # To store playlists for each user\n",
    "\n",
    "    for user_id in user_ids:\n",
    "        # Filter data for the user\n",
    "        user_data = data[data[\"user_id\"] == user_id].copy()\n",
    "\n",
    "        # Calculate distances\n",
    "        user_data.loc[:, \"distance\"] = user_data.apply(lambda row: compute_distance(row, prompt_features), axis=1)\n",
    "\n",
    "        recommended_songs = user_data.sort_values(by=\"distance\").head(num_songs)\n",
    "        recommended_uris = recommended_songs[\"uri\"].tolist()\n",
    "\n",
    "        song_names = get_song_names_from_url(recommended_uris)\n",
    "\n",
    "        # Store the playlist for the user\n",
    "        all_playlists[user_id] = song_names\n",
    "\n",
    "        # print(f\"\\nGenerated Playlist for User {user_id}:\")\n",
    "        # for song in song_names:\n",
    "        #     print(song)\n",
    "\n",
    "    return all_playlists\n",
    "\n",
    "prompt = \"dance songs to play at a Friday night disco party\"\n",
    "all_playlists = generate_playlists(prompt, num_songs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Playlists saved to user_playlists.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "def save_playlists_to_json(playlists, filename=\"playlists.json\"):\n",
    "    playlists_str_keys = {str(key): value for key, value in playlists.items()}\n",
    "    with open(filename, \"w\") as f:\n",
    "        json.dump(playlists_str_keys, f, indent=4)\n",
    "    print(f\"Playlists saved to {filename}\")\n",
    "\n",
    "save_playlists_to_json(all_playlists, filename=\"user_playlists.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.15 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0b5e19b0de7feeb6e6bb5f9738d975aa3f5dabb2cb545fec106b49f43b6978a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
