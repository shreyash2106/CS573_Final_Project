{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.22.4\n"
     ]
    }
   ],
   "source": [
    "!python -c \"import numpy; print(numpy.__version__)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "project_root = '../../src/'\n",
    "sys.path.insert(0, project_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_data = pd.read_csv('../../datasets/user_month_datasets/user1_1month_listening_history.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def preprocess_data(df):\n",
    "    \"\"\"\n",
    "    Preprocess the listening history to normalize features and prepare input for the RNN.\n",
    "    \"\"\"\n",
    "    # Define feature columns\n",
    "    feature_columns = [\n",
    "        'duration (ms)', 'danceability', 'energy', 'loudness', \n",
    "        'speechiness', 'acousticness', 'instrumentalness', \n",
    "        'liveness', 'valence', 'tempo', 'spec_rate'\n",
    "    ]\n",
    "    \n",
    "    # Normalize features\n",
    "    scaler = MinMaxScaler()\n",
    "    df[feature_columns] = scaler.fit_transform(df[feature_columns])\n",
    "    \n",
    "    # Convert the dataset into sequences for the RNN\n",
    "    sequences = df[feature_columns].values\n",
    "    \n",
    "    return sequences, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class RNNModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers=3, dropout=0.2):\n",
    "        super(RNNModel, self).__init__()\n",
    "        \n",
    "        # Define RNN with multiple layers\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, num_layers=num_layers, \n",
    "                           batch_first=True, dropout=dropout)\n",
    "        \n",
    "        # Layer normalization for stability\n",
    "        #self.layer_norm = nn.LayerNorm(hidden_size)\n",
    "        \n",
    "        # Fully connected layers for projection\n",
    "        self.fc1 = nn.Linear(hidden_size, hidden_size // 2)\n",
    "        self.fc2 = nn.Linear(hidden_size // 2, output_size)\n",
    "        \n",
    "        # Activation functions\n",
    "        self.relu = nn.ReLU()\n",
    "        self.tanh = nn.Tanh()\n",
    "        \n",
    "        # Dropout for regularization\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Pass input through RNN layers\n",
    "        _, hidden = self.rnn(x)\n",
    "        \n",
    "        # Take the last hidden state of the last RNN layer\n",
    "        hidden = hidden[-1]\n",
    "        \n",
    "        # Normalize the hidden state\n",
    "        #hidden = self.layer_norm(hidden)\n",
    "        \n",
    "        # Pass through fully connected layers with activation\n",
    "        out = self.fc1(hidden)\n",
    "        out = self.relu(out)\n",
    "        out = self.dropout(out)\n",
    "        \n",
    "        # Final projection to taste vector\n",
    "        taste_vector = self.fc2(out)\n",
    "        taste_vector = self.tanh(taste_vector)  # Optional, for bounded output\n",
    "        \n",
    "        return taste_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_rnn_model(model, train_loader, epochs=1000, learning_rate=0.001):\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        for sequences in train_loader:\n",
    "            sequences = sequences.float()\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(sequences)\n",
    "            weights = torch.arange(1, sequences.shape[1] + 1, device=sequences.device).float()\n",
    "            weights /= weights.sum()  # Normalize weights\n",
    "\n",
    "            # Compute weighted sum across the sequence\n",
    "            target_vector = (sequences * weights.unsqueeze(0).unsqueeze(-1)).sum(dim=1)\n",
    "            loss = criterion(outputs, target_vector)  # Predict the last song's vector\n",
    "            epoch_loss += loss.item()\n",
    "            \n",
    "            # Backward pass\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        #print(f\"Epoch {epoch + 1}, Loss: {epoch_loss / len(train_loader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from annoy import AnnoyIndex\n",
    "\n",
    "def build_annoy_index(song_vectors, num_trees=10):\n",
    "    \"\"\"\n",
    "    Build an Annoy index for nearest neighbor search.\n",
    "    \"\"\"\n",
    "    num_features = song_vectors.shape[1]\n",
    "    annoy_index = AnnoyIndex(num_features, 'euclidean')\n",
    "    \n",
    "    for i, vector in enumerate(song_vectors):\n",
    "        annoy_index.add_item(i, vector)\n",
    "    \n",
    "    annoy_index.build(num_trees)\n",
    "    return annoy_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "\n",
    "# Set up Spotify API credentials\n",
    "client_id = '75d0ab19dcdc4db7821a27bf07df72a0'  # Replace with your Spotify client ID\n",
    "client_secret = 'f64897e446834d7cb83b1c90916242df'  # Replace with your Spotify client secret\n",
    "\n",
    "# Authenticate with Spotify\n",
    "client_credentials_manager = SpotifyClientCredentials(client_id=client_id, client_secret=client_secret)\n",
    "sp = spotipy.Spotify(client_credentials_manager=client_credentials_manager)\n",
    "\n",
    "# Function to extract song name from Spotify URL\n",
    "def get_song_names_from_url(song_urls):\n",
    "    song_names = []\n",
    "    for i in range(len(song_urls)):\n",
    "        track_id = song_urls[i].split(\"/\")[-1].split(\"?\")[0]  # Extract the track ID from the URL\n",
    "        track_info = sp.track(track_id)  # Get track information\n",
    "        song_name = track_info['name']  # Extract song name\n",
    "        artist_name = track_info['artists'][0]['name']  # Extract artist name\n",
    "        song_names.append(f\"{song_name} by {artist_name}\")\n",
    "    return song_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_recommendations(taste_vector, annoy_index, song_metadata, k):\n",
    "    \"\"\"\n",
    "    Generate song recommendations by querying the Annoy index.\n",
    "    \"\"\"\n",
    "    # Get nearest song indices\n",
    "    nearest_indices = annoy_index.get_nns_by_vector(taste_vector, k, include_distances=False)\n",
    "    print(nearest_indices)\n",
    "    # Index into the song_metadata list directly\n",
    "    recommended_songs = [song_metadata[i] for i in nearest_indices]\n",
    "    return recommended_songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def save_playlists_to_json(playlists, filename=\"rnn_user_playlists.json\"):\n",
    "    with open(filename, \"w\") as f:\n",
    "        json.dump({str(user): playlist for user, playlist in playlists.items()}, f, indent=4)\n",
    "    print(f\"Playlists saved to {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "USER_DATASETS_FOLDER = \"../../datasets/user_month_datasets/\"\n",
    "MODELS_FOLDER = \"models\"\n",
    "os.makedirs(MODELS_FOLDER, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_models_for_all_users():\n",
    "    playlists = {}\n",
    "    for file in os.listdir(USER_DATASETS_FOLDER):\n",
    "        if file.endswith(\".csv\"):\n",
    "            user_id = file.split(\"_\")[0].replace(\"user\", \"\")\n",
    "            print(f\"Processing User {user_id}...\")\n",
    "            \n",
    "            # Load and preprocess data\n",
    "            user_data = pd.read_csv(os.path.join(USER_DATASETS_FOLDER, file))\n",
    "            user_data = user_data.sort_values(by=\"day\").drop(columns=[\"labels\", \"user_id\", \"group_no\"])\n",
    "            sequences, _ = preprocess_data(user_data)\n",
    "            train_loader = DataLoader(sequences, batch_size=1, shuffle=True)\n",
    "            \n",
    "            # Train RNN model\n",
    "            input_size = sequences.shape[1]\n",
    "            hidden_size = 128\n",
    "            output_size = sequences.shape[1]\n",
    "            model = RNNModel(input_size, hidden_size, output_size)\n",
    "            train_rnn_model(model, train_loader, epochs=15, learning_rate=0.01)\n",
    "\n",
    "            model_path = os.path.join(MODELS_FOLDER, f\"user_{user_id}_model.pth\")\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "            print(f\"Model saved for User {user_id} at {model_path}\")\n",
    "            \n",
    "def generate_playlists_for_all_users(num_songs=10):\n",
    "    playlists = {}\n",
    "    for file in os.listdir(USER_DATASETS_FOLDER):\n",
    "        if file.endswith(\".csv\"):\n",
    "            user_id = file.split(\"_\")[0].replace(\"user\", \"\")\n",
    "            print(f\"Generating playlist for User {user_id}...\")\n",
    "            \n",
    "            # Load the trained model\n",
    "            model_path = os.path.join(MODELS_FOLDER, f\"user_{user_id}_model.pth\")\n",
    "            if not os.path.exists(model_path):\n",
    "                print(f\"No trained model found for User {user_id}. Skipping...\")\n",
    "                continue\n",
    "            \n",
    "            # Load user data\n",
    "            user_data = pd.read_csv(os.path.join(USER_DATASETS_FOLDER, file))\n",
    "            user_data = user_data.sort_values(by=\"day\").drop(columns=[\"labels\", \"user_id\", \"group_no\"])\n",
    "            sequences, _ = preprocess_data(user_data)\n",
    "\n",
    "            input_size = sequences.shape[1]\n",
    "            hidden_size = 128\n",
    "            output_size = sequences.shape[1]\n",
    "            model = RNNModel(input_size, hidden_size, output_size)\n",
    "            model.load_state_dict(torch.load(model_path))\n",
    "            model.eval()\n",
    "            \n",
    "            # Generate taste vector\n",
    "            with torch.no_grad():\n",
    "                sequence_tensor = torch.tensor(sequences[0:1]).float()\n",
    "                taste_vector = model(sequence_tensor).squeeze(0).numpy()\n",
    "            \n",
    "            # Build Annoy index and generate recommendations\n",
    "            song_vectors = sequences\n",
    "            normalized_vectors = song_vectors / np.linalg.norm(song_vectors, axis=1, keepdims=True)\n",
    "            unique_vectors = np.array(list(set(map(tuple, normalized_vectors))))\n",
    "            annoy_index = build_annoy_index(unique_vectors)\n",
    "\n",
    "            song_metadata = user_data['uri'].tolist()\n",
    "            recommended_uris = generate_recommendations(taste_vector, annoy_index, song_metadata, k=num_songs)\n",
    "            recommended_songs = get_song_names_from_url(recommended_uris)\n",
    "            \n",
    "            playlists[user_id] = recommended_songs\n",
    "    \n",
    "    return playlists\n",
    "\n",
    "train_models_for_all_users()\n",
    "playlists = generate_playlists_for_all_users(num_songs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Playlists saved to rnn_user_playlists.json\n"
     ]
    }
   ],
   "source": [
    "save_playlists_to_json(playlists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df =  pd.read_csv('../../datasets/user1_1month_listening_history.csv')\n",
    "# Drop irrelevant columns\n",
    "df = df.drop(columns=[\"labels\", \"user_id\", \"group_no\"])\n",
    "df = df.sort_values(by=\"day\")\n",
    "\n",
    "# Preprocess data\n",
    "sequences, scaler = preprocess_data(df)\n",
    "\n",
    "# Prepare DataLoader\n",
    "train_loader = torch.utils.data.DataLoader(sequences, batch_size=1, shuffle=True)\n",
    "\n",
    "# Define and train the RNN model\n",
    "input_size = sequences.shape[1]  # Number of features\n",
    "hidden_size = 128  # Size of the hidden layer\n",
    "output_size = sequences.shape[1]  # Output is the same size as input\n",
    "model = RNNModel(input_size, hidden_size, output_size)\n",
    "train_rnn_model(model, train_loader, epochs=15, learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[520, 394, 560, 5, 417, 545, 508, 240, 335, 190]\n",
      "\n",
      "Recommended Songs:\n",
      "1. Black Water - Single Version by The Doobie Brothers\n",
      "2. The Paris of Nowhere by The Wonder Years\n",
      "3. Education by Private Productions\n",
      "4. Trains by Blippi\n",
      "5. Remembrance, Remembrance - Score by James Horner\n",
      "6. Tell Pencil to hmu let's collab by Deejay Chainwallet\n",
      "7. Beautiful People (feat. Carolina Liar) by Cher Lloyd\n",
      "8. Burden by Aminé\n",
      "9. Lemonade by Marco Nobel\n",
      "10. Cleanse Me (Search Me, O God) by Hymns on Piano\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "# sequence_tensor = torch.tensor(sequences).unsqueeze(0)  # Add batch dimension\n",
    "# sequence_tensor = sequence_tensor / torch.norm(sequence_tensor, dim=-1, keepdim=True)  # Normalize features\n",
    "\n",
    "with torch.no_grad():\n",
    "  sequence_tensor = torch.tensor(sequences[0:1]).float()\n",
    "  taste_vector = model(sequence_tensor.float()).squeeze(0).numpy()\n",
    "\n",
    "song_vectors = sequences\n",
    "normalized_vectors = song_vectors / np.linalg.norm(song_vectors, axis=1, keepdims=True)\n",
    "unique_vectors = np.array(list(set(map(tuple, normalized_vectors))))\n",
    "\n",
    "# Build the Annoy index\n",
    "annoy_index = build_annoy_index(unique_vectors)\n",
    "\n",
    "# Generate recommendations\n",
    "song_metadata = df['uri'].tolist()  # Convert 'uri' column to a list\n",
    "recommended_songs_uris = generate_recommendations(taste_vector, annoy_index, song_metadata, k=10)\n",
    "\n",
    "# Fetch song names using the Spotify API\n",
    "recommended_songs = get_song_names_from_url(recommended_songs_uris)\n",
    "\n",
    "# Display the recommended songs\n",
    "print(\"\\nRecommended Songs:\")\n",
    "for i, song in enumerate(recommended_songs, start=1):\n",
    "    print(f\"{i}. {song}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[479, 183, 713, 290, 126, 36, 85, 107, 203, 398]\n",
      "\n",
      "Recommended Songs:\n",
      "1. Quevedo: Bzrp Music Sessions, Vol. 52 by Sergio Rodríguez\n",
      "2. Dear Stranger by STRFKR\n",
      "3. Úton by Slow Village\n",
      "4. A Mí Me Esta Doliendo by Banda MS de Sergio Lizárraga\n",
      "5. Thrones of Blood by Sullivan King\n",
      "6. Let Live by Of Mice & Men\n",
      "7. Adagio by Secret Garden\n",
      "8. Después de Todo - Remasterizado by Juan Formell\n",
      "9. Education by Private Productions\n",
      "10. Forever Xe3 (Vibe Mashup) by Vibe\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "# sequence_tensor = torch.tensor(sequences).unsqueeze(0)  # Add batch dimension\n",
    "# sequence_tensor = sequence_tensor / torch.norm(sequence_tensor, dim=-1, keepdim=True)  # Normalize features\n",
    "\n",
    "with torch.no_grad():\n",
    "  sequence_tensor = torch.tensor(sequences[0:1]).float()\n",
    "  taste_vector = model(sequence_tensor.float()).squeeze(0).numpy()\n",
    "\n",
    "song_vectors = sequences\n",
    "normalized_vectors = song_vectors / np.linalg.norm(song_vectors, axis=1, keepdims=True)\n",
    "unique_vectors = np.array(list(set(map(tuple, normalized_vectors))))\n",
    "\n",
    "# Build the Annoy index\n",
    "annoy_index = build_annoy_index(unique_vectors)\n",
    "\n",
    "# Generate recommendations\n",
    "song_metadata = df['uri'].tolist()  # Convert 'uri' column to a list\n",
    "recommended_songs_uris = generate_recommendations(taste_vector, annoy_index, song_metadata, k=10)\n",
    "\n",
    "# Fetch song names using the Spotify API\n",
    "recommended_songs = get_song_names_from_url(recommended_songs_uris)\n",
    "\n",
    "# Display the recommended songs\n",
    "print(\"\\nRecommended Songs:\")\n",
    "for i, song in enumerate(recommended_songs, start=1):\n",
    "    print(f\"{i}. {song}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.15 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0b5e19b0de7feeb6e6bb5f9738d975aa3f5dabb2cb545fec106b49f43b6978a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
