{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.22.4\n"
     ]
    }
   ],
   "source": [
    "!python -c \"import numpy; print(numpy.__version__)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "project_root = '../../src/'\n",
    "sys.path.insert(0, project_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   duration (ms)  danceability  energy  loudness  speechiness  acousticness  \\\n",
      "0       125036.0      0.682982  0.4480  0.454525     0.582207      0.844378   \n",
      "1       251480.0      0.884331  0.5360  0.580489     0.582207      0.048293   \n",
      "2       129962.0      0.832923  0.5750  0.392388     0.582207      0.018976   \n",
      "3       219333.0      0.358466  0.0525  0.467604     0.735099      0.897590   \n",
      "4       175733.0      0.716183  0.2920  0.535565     0.582207      0.292169   \n",
      "\n",
      "   instrumentalness  liveness  valence     tempo     spec_rate  labels  \\\n",
      "0          0.000000  0.188416    0.579  0.825227  4.754654e-07     0.0   \n",
      "1          0.000135  0.179196    0.744  0.601342  7.754096e-07     1.0   \n",
      "2          0.004970  0.447321    0.621  0.664681  4.754654e-07     2.0   \n",
      "3          0.177000  0.447321    0.036  0.561521  5.060798e-07     0.0   \n",
      "4          0.000748  0.546099    0.524  0.293744  4.754654e-07     0.0   \n",
      "\n",
      "                                    uri  user_id  group_no  day  \n",
      "0  spotify:track:0N57cNe2pMnZlDZsHPBpKR        1         2    1  \n",
      "1  spotify:track:79q5QdhFyadSwFzOZJ9ymG        1         2    1  \n",
      "2  spotify:track:1u6jmEdKp71ku0bgkuns7D        1         2    1  \n",
      "3  spotify:track:2BgvPUl8mpLAa2ABzHrEtO        1         2    1  \n",
      "4  spotify:track:2S8sebSU3YRqFdD7IZw7le        1         2    1  \n"
     ]
    }
   ],
   "source": [
    "user_data = pd.read_csv('../../datasets/user_month_datasets/user1_1month_listening_history.csv')\n",
    "print(user_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def preprocess_data(df):\n",
    "    \"\"\"\n",
    "    Preprocess the listening history to normalize features and prepare input for the RNN.\n",
    "    \"\"\"\n",
    "    # Define feature columns\n",
    "    feature_columns = [\n",
    "        'duration (ms)', 'danceability', 'energy', 'loudness', \n",
    "        'speechiness', 'acousticness', 'instrumentalness', \n",
    "        'liveness', 'valence', 'tempo', 'spec_rate'\n",
    "    ]\n",
    "    \n",
    "    # Normalize features\n",
    "    scaler = MinMaxScaler()\n",
    "    df[feature_columns] = scaler.fit_transform(df[feature_columns])\n",
    "    \n",
    "    # Convert the dataset into sequences for the RNN\n",
    "    sequences = df[feature_columns].values\n",
    "    \n",
    "    return sequences, scaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class RNNModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers=3, dropout=0.2):\n",
    "        super(RNNModel, self).__init__()\n",
    "        \n",
    "        # Define RNN with multiple layers\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, num_layers=num_layers, \n",
    "                           batch_first=True, dropout=dropout)\n",
    "        \n",
    "        # Layer normalization for stability\n",
    "        #self.layer_norm = nn.LayerNorm(hidden_size)\n",
    "        \n",
    "        # Fully connected layers for projection\n",
    "        self.fc1 = nn.Linear(hidden_size, hidden_size // 2)\n",
    "        self.fc2 = nn.Linear(hidden_size // 2, output_size)\n",
    "        \n",
    "        # Activation functions\n",
    "        self.relu = nn.ReLU()\n",
    "        self.tanh = nn.Tanh()\n",
    "        \n",
    "        # Dropout for regularization\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Pass input through RNN layers\n",
    "        _, hidden = self.rnn(x)\n",
    "        \n",
    "        # Take the last hidden state of the last RNN layer\n",
    "        hidden = hidden[-1]\n",
    "        \n",
    "        # Normalize the hidden state\n",
    "        #hidden = self.layer_norm(hidden)\n",
    "        \n",
    "        # Pass through fully connected layers with activation\n",
    "        out = self.fc1(hidden)\n",
    "        out = self.relu(out)\n",
    "        out = self.dropout(out)\n",
    "        \n",
    "        # Final projection to taste vector\n",
    "        taste_vector = self.fc2(out)\n",
    "        taste_vector = self.tanh(taste_vector)  # Optional, for bounded output\n",
    "        \n",
    "        return taste_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_rnn_model(model, train_loader, epochs=1000, learning_rate=0.001):\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        for sequences in train_loader:\n",
    "            sequences = sequences.float()\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(sequences)\n",
    "            weights = torch.arange(1, sequences.shape[1] + 1, device=sequences.device).float()\n",
    "            weights /= weights.sum()  # Normalize weights\n",
    "\n",
    "            # Compute weighted sum across the sequence\n",
    "            target_vector = (sequences * weights.unsqueeze(0).unsqueeze(-1)).sum(dim=1)\n",
    "            loss = criterion(outputs, target_vector)  # Predict the last song's vector\n",
    "            epoch_loss += loss.item()\n",
    "            \n",
    "            # Backward pass\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        print(f\"Epoch {epoch + 1}, Loss: {epoch_loss / len(train_loader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from annoy import AnnoyIndex\n",
    "\n",
    "def build_annoy_index(song_vectors, num_trees=10):\n",
    "    \"\"\"\n",
    "    Build an Annoy index for nearest neighbor search.\n",
    "    \"\"\"\n",
    "    num_features = song_vectors.shape[1]\n",
    "    annoy_index = AnnoyIndex(num_features, 'euclidean')\n",
    "    \n",
    "    for i, vector in enumerate(song_vectors):\n",
    "        annoy_index.add_item(i, vector)\n",
    "    \n",
    "    annoy_index.build(num_trees)\n",
    "    return annoy_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "\n",
    "# Set up Spotify API credentials\n",
    "client_id = '75d0ab19dcdc4db7821a27bf07df72a0'  # Replace with your Spotify client ID\n",
    "client_secret = 'f64897e446834d7cb83b1c90916242df'  # Replace with your Spotify client secret\n",
    "\n",
    "# Authenticate with Spotify\n",
    "client_credentials_manager = SpotifyClientCredentials(client_id=client_id, client_secret=client_secret)\n",
    "sp = spotipy.Spotify(client_credentials_manager=client_credentials_manager)\n",
    "\n",
    "# Function to extract song name from Spotify URL\n",
    "def get_song_names_from_url(song_urls):\n",
    "    song_names = []\n",
    "    for i in range(len(song_urls)):\n",
    "        track_id = song_urls[i].split(\"/\")[-1].split(\"?\")[0]  # Extract the track ID from the URL\n",
    "        track_info = sp.track(track_id)  # Get track information\n",
    "        song_name = track_info['name']  # Extract song name\n",
    "        artist_name = track_info['artists'][0]['name']  # Extract artist name\n",
    "        song_names.append(f\"{song_name} by {artist_name}\")\n",
    "    return song_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_recommendations(taste_vector, annoy_index, song_metadata, k):\n",
    "    \"\"\"\n",
    "    Generate song recommendations by querying the Annoy index.\n",
    "    \"\"\"\n",
    "    # Get nearest song indices\n",
    "    nearest_indices = annoy_index.get_nns_by_vector(taste_vector, k, include_distances=False)\n",
    "    print(nearest_indices)\n",
    "    # Index into the song_metadata list directly\n",
    "    recommended_songs = [song_metadata[i] for i in nearest_indices]\n",
    "    return recommended_songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/siyengar/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([1, 11])) that is different to the input size (torch.Size([11])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.0304\n",
      "Epoch 2, Loss: 0.0142\n",
      "Epoch 3, Loss: 0.0102\n",
      "Epoch 4, Loss: 0.0094\n",
      "Epoch 5, Loss: 0.0091\n",
      "Epoch 6, Loss: 0.0090\n",
      "Epoch 7, Loss: 0.0085\n",
      "Epoch 8, Loss: 0.0085\n",
      "Epoch 9, Loss: 0.0085\n",
      "Epoch 10, Loss: 0.0081\n",
      "Epoch 11, Loss: 0.0081\n",
      "Epoch 12, Loss: 0.0079\n",
      "Epoch 13, Loss: 0.0083\n",
      "Epoch 14, Loss: 0.0077\n",
      "Epoch 15, Loss: 0.0076\n"
     ]
    }
   ],
   "source": [
    "df =  pd.read_csv('../../datasets/user1_1month_listening_history.csv')\n",
    "# Drop irrelevant columns\n",
    "df = df.drop(columns=[\"labels\", \"user_id\", \"group_no\"])\n",
    "df = df.sort_values(by=\"day\")\n",
    "\n",
    "# Preprocess data\n",
    "sequences, scaler = preprocess_data(df)\n",
    "\n",
    "# Prepare DataLoader\n",
    "train_loader = torch.utils.data.DataLoader(sequences, batch_size=1, shuffle=True)\n",
    "\n",
    "# Define and train the RNN model\n",
    "input_size = sequences.shape[1]  # Number of features\n",
    "hidden_size = 128  # Size of the hidden layer\n",
    "output_size = sequences.shape[1]  # Output is the same size as input\n",
    "model = RNNModel(input_size, hidden_size, output_size)\n",
    "train_rnn_model(model, train_loader, epochs=15, learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[520, 394, 560, 5, 417, 545, 508, 240, 335, 190]\n",
      "\n",
      "Recommended Songs:\n",
      "1. Black Water - Single Version by The Doobie Brothers\n",
      "2. The Paris of Nowhere by The Wonder Years\n",
      "3. Education by Private Productions\n",
      "4. Trains by Blippi\n",
      "5. Remembrance, Remembrance - Score by James Horner\n",
      "6. Tell Pencil to hmu let's collab by Deejay Chainwallet\n",
      "7. Beautiful People (feat. Carolina Liar) by Cher Lloyd\n",
      "8. Burden by Aminé\n",
      "9. Lemonade by Marco Nobel\n",
      "10. Cleanse Me (Search Me, O God) by Hymns on Piano\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "# sequence_tensor = torch.tensor(sequences).unsqueeze(0)  # Add batch dimension\n",
    "# sequence_tensor = sequence_tensor / torch.norm(sequence_tensor, dim=-1, keepdim=True)  # Normalize features\n",
    "\n",
    "with torch.no_grad():\n",
    "  sequence_tensor = torch.tensor(sequences[0:1]).float()\n",
    "  taste_vector = model(sequence_tensor.float()).squeeze(0).numpy()\n",
    "\n",
    "song_vectors = sequences\n",
    "normalized_vectors = song_vectors / np.linalg.norm(song_vectors, axis=1, keepdims=True)\n",
    "unique_vectors = np.array(list(set(map(tuple, normalized_vectors))))\n",
    "\n",
    "# Build the Annoy index\n",
    "annoy_index = build_annoy_index(unique_vectors)\n",
    "\n",
    "# Generate recommendations\n",
    "song_metadata = df['uri'].tolist()  # Convert 'uri' column to a list\n",
    "recommended_songs_uris = generate_recommendations(taste_vector, annoy_index, song_metadata, k=10)\n",
    "\n",
    "# Fetch song names using the Spotify API\n",
    "recommended_songs = get_song_names_from_url(recommended_songs_uris)\n",
    "\n",
    "# Display the recommended songs\n",
    "print(\"\\nRecommended Songs:\")\n",
    "for i, song in enumerate(recommended_songs, start=1):\n",
    "    print(f\"{i}. {song}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[479, 183, 713, 290, 126, 36, 85, 107, 203, 398]\n",
      "\n",
      "Recommended Songs:\n",
      "1. Quevedo: Bzrp Music Sessions, Vol. 52 by Sergio Rodríguez\n",
      "2. Dear Stranger by STRFKR\n",
      "3. Úton by Slow Village\n",
      "4. A Mí Me Esta Doliendo by Banda MS de Sergio Lizárraga\n",
      "5. Thrones of Blood by Sullivan King\n",
      "6. Let Live by Of Mice & Men\n",
      "7. Adagio by Secret Garden\n",
      "8. Después de Todo - Remasterizado by Juan Formell\n",
      "9. Education by Private Productions\n",
      "10. Forever Xe3 (Vibe Mashup) by Vibe\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "# sequence_tensor = torch.tensor(sequences).unsqueeze(0)  # Add batch dimension\n",
    "# sequence_tensor = sequence_tensor / torch.norm(sequence_tensor, dim=-1, keepdim=True)  # Normalize features\n",
    "\n",
    "with torch.no_grad():\n",
    "  sequence_tensor = torch.tensor(sequences[0:1]).float()\n",
    "  taste_vector = model(sequence_tensor.float()).squeeze(0).numpy()\n",
    "\n",
    "song_vectors = sequences\n",
    "normalized_vectors = song_vectors / np.linalg.norm(song_vectors, axis=1, keepdims=True)\n",
    "unique_vectors = np.array(list(set(map(tuple, normalized_vectors))))\n",
    "\n",
    "# Build the Annoy index\n",
    "annoy_index = build_annoy_index(unique_vectors)\n",
    "\n",
    "# Generate recommendations\n",
    "song_metadata = df['uri'].tolist()  # Convert 'uri' column to a list\n",
    "recommended_songs_uris = generate_recommendations(taste_vector, annoy_index, song_metadata, k=10)\n",
    "\n",
    "# Fetch song names using the Spotify API\n",
    "recommended_songs = get_song_names_from_url(recommended_songs_uris)\n",
    "\n",
    "# Display the recommended songs\n",
    "print(\"\\nRecommended Songs:\")\n",
    "for i, song in enumerate(recommended_songs, start=1):\n",
    "    print(f\"{i}. {song}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.15 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0b5e19b0de7feeb6e6bb5f9738d975aa3f5dabb2cb545fec106b49f43b6978a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
