{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "project_root = '../../src/'\n",
    "sys.path.insert(0, project_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../../datasets/seven_day_listening_history.csv.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [34], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m user_data \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m../../datasets/seven_day_listening_history.csv.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(user_data\u001b[38;5;241m.\u001b[39mhead())\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[1;32m    306\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    307\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39marguments),\n\u001b[1;32m    308\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[1;32m    309\u001b[0m         stacklevel\u001b[39m=\u001b[39mstacklevel,\n\u001b[1;32m    310\u001b[0m     )\n\u001b[0;32m--> 311\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py:678\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    663\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    664\u001b[0m     dialect,\n\u001b[1;32m    665\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    674\u001b[0m     defaults\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mdelimiter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[1;32m    675\u001b[0m )\n\u001b[1;32m    676\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 678\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py:575\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    572\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[1;32m    574\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 575\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    577\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[1;32m    578\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py:932\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    929\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m    931\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 932\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1216\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1212\u001b[0m     mode \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1213\u001b[0m \u001b[39m# error: No overload variant of \"get_handle\" matches argument types\u001b[39;00m\n\u001b[1;32m   1214\u001b[0m \u001b[39m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[39;00m\n\u001b[1;32m   1215\u001b[0m \u001b[39m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[39;00m\n\u001b[0;32m-> 1216\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(  \u001b[39m# type: ignore[call-overload]\u001b[39;49;00m\n\u001b[1;32m   1217\u001b[0m     f,\n\u001b[1;32m   1218\u001b[0m     mode,\n\u001b[1;32m   1219\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1220\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1221\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[1;32m   1222\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[1;32m   1223\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m   1224\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1225\u001b[0m )\n\u001b[1;32m   1226\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1227\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/common.py:786\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    781\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[1;32m    782\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    783\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    784\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[1;32m    785\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[0;32m--> 786\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[1;32m    787\u001b[0m             handle,\n\u001b[1;32m    788\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[1;32m    789\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[1;32m    790\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[1;32m    791\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    792\u001b[0m         )\n\u001b[1;32m    793\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    794\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[1;32m    795\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../../datasets/seven_day_listening_history.csv.csv'"
     ]
    }
   ],
   "source": [
    "user_data = pd.read_csv('../../datasets/seven_day_listening_history.csv')\n",
    "print(user_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse.linalg import svds\n",
    "\n",
    "def create_user_item_matrix(df):\n",
    "    \"\"\"\n",
    "    Step 1: Create the user-item matrix\n",
    "    - Rows represent users\n",
    "    - Columns represent songs (items)\n",
    "    - Values represent the interaction score\n",
    "    \"\"\"\n",
    "    # First, let's create an interaction score based on the features\n",
    "    feature_columns = [\n",
    "        'danceability', 'energy', 'loudness', 'speechiness',\n",
    "        'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo',\n",
    "        'duration (ms)', 'spec_rate', 'labels'\n",
    "    ]\n",
    "    \n",
    "    # Create an interaction score (average of normalized features)\n",
    "    df['interaction_score'] = np.mean(df[feature_columns], axis=1)\n",
    "    \n",
    "    # Create the user-item matrix\n",
    "    user_item_matrix = df.pivot_table(\n",
    "        index='user_id',\n",
    "        columns='uri',\n",
    "        values='interaction_score',\n",
    "        fill_value=0\n",
    "    )\n",
    "    \n",
    "    return user_item_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def perform_svd(matrix, k=10):\n",
    "    \"\"\"\n",
    "    Step 2: Perform SVD on the matrix\n",
    "    - Decompose matrix into U, Sigma, and V matrices\n",
    "    - k is the number of latent factors\n",
    "    \"\"\"\n",
    "    # Convert to numpy array\n",
    "    matrix_numpy = matrix.values\n",
    "    \n",
    "    # Center the matrix (subtract mean)\n",
    "    matrix_mean = np.mean(matrix_numpy, axis=1)\n",
    "    matrix_centered = matrix_numpy - matrix_mean.reshape(-1, 1)\n",
    "    \n",
    "    # Perform SVD\n",
    "    U, sigma, Vt = svds(matrix_centered, k=k)\n",
    "    \n",
    "    # Convert sigma to diagonal matrix\n",
    "    sigma = np.diag(sigma)\n",
    "    \n",
    "    return U, sigma, Vt, matrix_mean\n",
    "\n",
    "def reconstruct_matrix(U, sigma, Vt, matrix_mean):\n",
    "    \"\"\"\n",
    "    Step 3: Reconstruct the matrix to get predictions\n",
    "    - Multiply U, sigma, and V transpose\n",
    "    - Add back the mean\n",
    "    \"\"\"\n",
    "    # Reconstruct the matrix\n",
    "    predictions = np.dot(np.dot(U, sigma), Vt)\n",
    "    \n",
    "    # Add the mean back\n",
    "    predictions += matrix_mean.reshape(-1, 1)\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "def get_recommendations(predictions, user_item_matrix, user_id, n_recommendations=5):\n",
    "    \"\"\"\n",
    "    Step 4: Generate recommendations for a user\n",
    "    - Find songs the user hasn't interacted with\n",
    "    - Rank them by predicted score\n",
    "    \"\"\"\n",
    "    # Get user index\n",
    "    user_idx = user_item_matrix.index.get_loc(user_id)\n",
    "    \n",
    "    # Get song indices and names\n",
    "    song_indices = np.arange(user_item_matrix.shape[1])\n",
    "    song_names = user_item_matrix.columns\n",
    "    \n",
    "    # Get user's predictions\n",
    "    user_predictions = predictions[user_idx]\n",
    "    \n",
    "    # Get indices of songs user hasn't interacted with\n",
    "    user_songs = user_item_matrix.iloc[user_idx].values\n",
    "    unlistened_songs = song_indices[user_songs == 0]\n",
    "    \n",
    "    # Get predictions for unlistened songs\n",
    "    unlistened_predictions = user_predictions[unlistened_songs]\n",
    "    \n",
    "    # Get top N recommendations\n",
    "    top_n_idx = np.argsort(unlistened_predictions)[-n_recommendations:][::-1]\n",
    "    recommended_song_indices = unlistened_songs[top_n_idx]\n",
    "    recommended_songs = song_names[recommended_song_indices]\n",
    "    \n",
    "    return recommended_songs, user_predictions[recommended_song_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "\n",
    "# Set up Spotify API credentials\n",
    "client_id = '75d0ab19dcdc4db7821a27bf07df72a0'  # Replace with your Spotify client ID\n",
    "client_secret = 'f64897e446834d7cb83b1c90916242df'  # Replace with your Spotify client secret\n",
    "\n",
    "# Authenticate with Spotify\n",
    "client_credentials_manager = SpotifyClientCredentials(client_id=client_id, client_secret=client_secret)\n",
    "sp = spotipy.Spotify(client_credentials_manager=client_credentials_manager)\n",
    "\n",
    "# Function to extract song name from Spotify URL\n",
    "def get_song_names_from_url(song_urls):\n",
    "    song_names = []\n",
    "    for i in range(len(song_urls)):\n",
    "        track_id = song_urls[i].split(\"/\")[-1].split(\"?\")[0]  # Extract the track ID from the URL\n",
    "        track_info = sp.track(track_id)  # Get track information\n",
    "        song_name = track_info['name']  # Extract song name\n",
    "        artist_name = track_info['artists'][0]['name']  # Extract artist name\n",
    "        song_names.append(f\"{song_name} by {artist_name}\")\n",
    "    return song_names\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from constants.constants import group_mood_mapping\n",
    "\n",
    "def main_svd_pipeline(df, n_factors=10):\n",
    "    \"\"\"\n",
    "    Run the complete SVD pipeline\n",
    "    \"\"\"\n",
    "    # Step 1: Create user-item matrix\n",
    "    print(\"Creating user-item matrix...\")\n",
    "    user_item_matrix = create_user_item_matrix(df)\n",
    "    print(f\"Matrix shape: {user_item_matrix.shape}\")\n",
    "    \n",
    "    # Step 2: Perform SVD\n",
    "    print(\"\\nPerforming SVD...\")\n",
    "    U, sigma, Vt, matrix_mean = perform_svd(user_item_matrix, k=n_factors)\n",
    "    print(f\"U shape: {U.shape}\")\n",
    "    print(f\"Sigma shape: {sigma.shape}\")\n",
    "    print(f\"V^T shape: {Vt.shape}\")\n",
    "    \n",
    "    # Step 3: Generate predictions\n",
    "    print(\"\\nGenerating predictions...\")\n",
    "    predictions = reconstruct_matrix(U, sigma, Vt, matrix_mean)\n",
    "    \n",
    "    return user_item_matrix, predictions\n",
    "\n",
    "# Example usage\n",
    "def demonstrate_recommendations(df):\n",
    "    \"\"\"\n",
    "    Demonstrate the recommendation system\n",
    "    \"\"\"\n",
    "    # Run SVD pipeline\n",
    "    user_item_matrix, predictions = main_svd_pipeline(df)\n",
    "    \n",
    "    # Get recommendations for a sample user\n",
    "    i = np.random.randint(user_item_matrix.shape[0])\n",
    "    sample_user = user_item_matrix.index[i]\n",
    "    group_no = df.loc[df['user_id'] == sample_user, 'group_no'].iloc[0]\n",
    "    print(f\"\\nGetting recommendations for user {sample_user} from group {group_no} {group_mood_mapping[group_no]}...\")\n",
    "    recommended_songs, pred_scores = get_recommendations(\n",
    "        predictions, \n",
    "        user_item_matrix, \n",
    "        sample_user\n",
    "    )\n",
    "    recommended_songs = get_song_names_from_url(recommended_songs)\n",
    "    print(f\"\\n {recommended_songs}\")\n",
    "    \n",
    "    return recommended_songs, pred_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating user-item matrix...\n",
      "Matrix shape: (100, 83654)\n",
      "\n",
      "Performing SVD...\n",
      "U shape: (100, 10)\n",
      "Sigma shape: (10, 10)\n",
      "V^T shape: (10, 83654)\n",
      "\n",
      "Generating predictions...\n",
      "\n",
      "Getting recommendations for user 28 from group 3 Energetic...\n",
      "\n",
      " ['The Feeling (Of Warmth And Beauty) by Richard H. Kirk', 'Sad Songs (Say So Much) by Elton John', 'E Quella Notte Danzammo Dinanzi Alla Luna by Elica Mayres', 'My Dad And Who The F... Is Wifi by Kevin Hart', 'Beach Runner - Manuel Darquart Balearic Rerub by Pacific Coliseum']\n"
     ]
    }
   ],
   "source": [
    "recommended_songs, pred_scores = demonstrate_recommendations(user_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
